# === Wybór urządzenia do obliczeń ===
device: "cpu" # "cuda" dla karty graficznej NVIDIA, "cpu" dla procesora

# === Detektor ===
detector:
  min_confidence: 0.5 # Minimalna pewność detekcji twarzy (0–1)
  min_face_size: 200 # Minimalny rozmiar wykrywanej twarzy (w px); większy = tylko bliskie twarze

# === Logika tworzenia zdjęć do analizy ===
capturer:
  min_look_time: 1.0 # Minimalny czas patrzenia w kamerę (w sekundach)
  symmetry_threshold: 10 # Maksymalna tolerancja przekręcenia głowy (px różnicy położenia nosa względem oczu/ust)
  debounce_time: 2.0 # Minimalny czas pomiędzy kolejnymi ujęciami (w sekundach)
  check_is_facing: false # Czy wymagać patrzenia prosto w kamerę? (true/false)

# === Tworzenie embeddingu ===
embedder:
  image_size: 160 # Rozmiar wejściowy twarzy dla modelu
  post_process: true # Czy stosować normalizację MTCNN (zalecane)
  margin: 0 # Margines wokół twarzy – większy = więcej tła

# === Uwierzytelnienie ===
authenticator:
  embedding_dim: 512 # Wymiar embeddingu (zgodny z modelem)
  threshold: 0.8 # Próg odległości L2 – im mniejszy, tym trudniej o dopasowanie

# === Baza danych ===
database:
  db_path: "db/faces.db" # Ścieżka do pliku SQLite z embeddingami
  embedding_dim: 512 # Wymiar embeddingu (musi pasować do modelu)

# === Różne ===
misc:
  verbose: false # Czy wypisywać dodatkowe informacje o przebiegu działania systemu?

  # === Wejście wideo ===
  video:
    mode: "file" # "live" - kamera na żywo, "file" - analiza nagranego pliku
    video_path: "videos/05-04-2025/video-18-22-12.avi" # Ścieżka do pliku wideo (gdy mode == "file")
    record_video: true # Czy zapisywać sesję wideo (działa tylko w trybie "live")
    output_path: "" # Ścieżka do pliku wyjściowego z nagraniem; jeśli puste, generowana będzie dynamicznie
